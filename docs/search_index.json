[["index.html", "Inferência =) Capítulo 1 Introdução 1.1 Definições 1.2 Amostra Aleatória Simples 1.3 Estatísticas particularidades", " Inferência =) Thalis Rebouças Última atualização: 21/10/2021 Capítulo 1 Introdução Esse será um Livro para ajudar na cadeira de inferência !!! As duas principais definições básicas em Inferência Estatística são as de população e amostra. Esses são os dois conceitos que são repetidos inúmeras vezes nesse material e que são explanados a seguir. 1.1 Definições Seja X uma variável aleatória (v.a.) com função de densidade (ou de probabilidade) \\(f (x|\\theta)\\), em que \\(\\theta\\) é um parâmetro desconhecido. Chamamos de inferência estatística o problema que consiste em especificar um ou mais valores para \\(\\theta\\), baseado em um conjunto de valores observados de X. População O conjunto de valores de uma característica (observável) associada auma coleção de indivíduos ou objetos de interesse é dito ser uma população. Amostra É um conjunto de dados coletados e/ou selecionados de uma populaçãopor um procedimento definido. Os elementos de uma amostra são conhecidos como pontos amostrais,unidades amostrais ou observações.É qualquer subconjunto da população. É, portanto, a partir da amostra \\(X_1,X_2,...,X_n\\) que conseguimos obter informação sobre o parâmetro \\(\\theta\\) de interesse. Mas como ainda não sabemos o que é um parâmetro, vamos explicar na próxima seção. Estatísticas Uma estatística é uma característica da amostra, ou seja, uma estatística T é uma função de \\(X_1,X_2,...,X_n\\) , não depende de parâmetros desconhecidos A média, a mediana, o mínimo e o máximo, por exemplo, são exemplos de estatísticas!!! Parâmetro Um parâmetro é uma medida usada para descrever uma característica da população.Em geral são desconhecidos e têm-se o objetivo de estimá-los. Considere uma população identificada pela v.a X, seriam parâmetros a média E(X) e sua variância Var(X) Espaço Parâmetro Seja \\(X_1,X_2,...,X_n\\) uma amostra aleatória de uma variávelaleatória com distribuição \\(f(X_i;\\theta)\\), em que \\(\\theta\\) é o parâmetro associado à distribuição. O intervalo \\(\\Theta\\) de valores possíveis para \\(\\theta\\) é chamado espaço paramétrico. Estimador Um estimador é uma estatística cujas realizações são utilizadas para obter estimações dos parâmetros de um modelo probabilístico e uma realização ou um valor particular se conhece como estimação. A estatística que assuma qualquer valor em \\(\\Theta\\) é uma estimador para \\(\\theta\\). 1.2 Amostra Aleatória Simples Seja X uma variável aleatória com distribuição de probabilidade ou função densidade de probabilidade \\(f (x|\\theta)\\). Sejam \\(X_1,X_2,...,X_n\\) variáveis aleató-rias independentes e identicamente distribuídas, indicandonretiradas de uma população P. Então, \\(X_1,X_2,...,X_n\\) é uma amostra aleatória simples de P. Perceba que quando coletamos as observações por meio da amostra aleatória simples, podemos afirmar que temos uma amostra de variáveis aleatórias independentes (a retirada de uma observação não tem relação com a retirada de nenhuma outra) e identicamente distribuídas (cada observação tem a mesma distribuição deprobabildiade ou função densidade de probabilidade). A partir dessas duas características, podemos encontrara distribuição conjunta dessa amostra, que é apresentada formalmente a seguir. 1.2.1 Distribuição da amostral Seja \\(X_1,X_2,...,X_n\\) numa amostra aleatória de umavariável aleatória com distribuição \\(f (x_i|\\theta)\\). A distribuição da respectiva amostra é a distribuição conjuntade \\(X_1,X_2,...,X_n\\) dada por: \\[f_{(X_1,X_2,...,X_n)} = f_{X_1}(x_1;\\theta) f_{X_2}(x_2;\\theta) \\ldots f_{X_3}(x_3;\\theta) \\] \\[ = \\prod_{k=1}^{n} f_{X_k}(x_k;\\theta) \\] A essa distribuição conjunta dá-se o nome de função de verossimilhança. 1.3 Estatísticas particularidades 1.3.1 Estatística suficiente Dentre todas as estatísticas, nesta subseção vamos estudar aquela que a literatura chama de estatística suficiente, cuja quantidade permite um resumo das informações trazidas pela amostra, sendo capaz de resumiros dados sem perder nenhuma informação sobre \\(\\theta\\) . Definição: Seja \\(X_1,X_2,...,X_n\\) uma amostra aleatória de uma população com função de probabilidade ou função densidade de probabilidade \\(f(X|\\theta)\\), com \\(\\theta \\in \\Theta\\). A estatística \\(T=T(X_1,X_2,...,X_n)\\) é dita ser suficiente para \\(\\theta\\) se, e somente se, a distribuição conjuntade \\((X_1,X_2,...,X_n)\\) dado T=t não depende de \\(\\theta\\). Podemos afirmar, nesse sentido, que, conhecida uma estatística suficiente, os dados da amostra passama ser desconsiderados ou irrelevantes, dado que não há mais informações adicionais a serem retiradas sobre oparâmetro de interesse, embora ainda possa conter informações relevantes sobre o modelo estatístico. "],["estimação-pontual.html", "Capítulo 2 Estimação pontual 2.1 Método dos momentos 2.2 Método da máxima verossimilhança 2.3 método dos mínimos quadrados 2.4 Eficiência de estimadores", " Capítulo 2 Estimação pontual 2.1 Método dos momentos 2.2 Método da máxima verossimilhança 2.3 método dos mínimos quadrados 2.4 Eficiência de estimadores "],["estatística-suficiente-e-família-exponencial-.html", "Capítulo 3 Estatística suficiente e família exponencial. 3.1 Estimação intervalar", " Capítulo 3 Estatística suficiente e família exponencial. 3.1 Estimação intervalar "],["formulario.html", "Capítulo 4 Formulario 4.1 Estatísticas 4.2 Parametros", " Capítulo 4 Formulario 4.1 Estatísticas Considere uma amostra aleatória \\(X_1,X_2,...,X_n\\) de uma variável aleatória X. As estatísticas mais comuns são: \\[ \\text{Média amostral : } \\; \\bar{X}= \\dfrac{1}{n} \\sum_{i=1}^{n}X_i \\\\ \\text{Variância amostral : } \\; S^2 = \\dfrac{1}{n-1} \\sum_{i=1}^{n}(X_i-\\bar{X})^2 \\\\ \\text{Menor valor amostral : } \\; X_1 = min(X_1,X_2,...,X_n) \\\\ \\text{Mair valor amostral : } \\; X_n = max(X_1,X_2,...,X_n) \\\\ \\text{Amplitude amostral : } W = X_n-X_1 \\] 4.2 Parametros Estatística Amostra População Média \\(\\bar{X}\\) \\(E(X)= \\mu\\) Mediana \\(md = q_2\\) \\(Md = Q_2\\) Variância \\(S^2\\) \\(Var(X) = \\sigma^2\\) Tamanho \\(n\\) \\(N\\) Proporção \\(\\hat{p}\\) \\(p\\) Quartis \\(q_1,q_2,q_3\\) \\(Q_1,Q_2,Q_3\\) Função densidade histograma \\(f(X)\\) Função Acumulada \\(F_e(X)\\) \\(F(X)\\) "],["references.html", "References", " References M. C. Bolfarine, H. &amp; Sandoval. Introdução a Inferência Estatística. SBM, 2001. P. A. Bussab, W. O. &amp; Morettin. Estatística Básica. Saraiva, 2014. R. Casella, G.; Berger. Statistical Inference. Duxbury/Thomson Learning, 2002. J. L. Devore. Probabilidade e Estatística para Engenharia e Ciências. Cenfigage, 2018. F.; Boes D. Mood, A.; Graybill. Introduction to the Theory of Statistics. McGraw-Hill, 1974. "]]
